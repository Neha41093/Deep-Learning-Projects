{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_SpeechDenoising_1DCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8DpI4-2KkrHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Speech Denoising using 1D CNN**"
      ]
    },
    {
      "metadata": {
        "id": "yP1W-dpmki2r",
        "colab_type": "code",
        "outputId": "603d4742-d929-4474-df63-977bd1d5d38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa # in colab, you'll need to install this\n",
        "import librosa"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.27.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "10P-R0K3bGBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "from __future__ import print_function, absolute_import, division\n",
        "from ipywidgets import interact, interactive, fixed\n",
        "import ipywidgets as widgets\n",
        "from math import ceil\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pl9k8AaobJ70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wljwBeGbNNn",
        "colab_type": "code",
        "outputId": "5173c04e-a5e8-4b50-f0d2-5df0c8f5eede",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-07e6efb5-8eae-42ec-bfeb-dd1c159f5fda\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-07e6efb5-8eae-42ec-bfeb-dd1c159f5fda\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_x_01.wav to test_x_01 (1).wav\n",
            "Saving test_x_02.wav to test_x_02 (1).wav\n",
            "Saving train_clean_male.wav to train_clean_male (1).wav\n",
            "Saving train_dirty_male.wav to train_dirty_male (1).wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w3rARog8bX1T",
        "colab_type": "code",
        "outputId": "b9dea3b1-2371-4e11-cb49-447678108627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"test_x_01.wav\" with length 145284 bytes\n",
            "User uploaded file \"test_x_02.wav\" with length 388752 bytes\n",
            "User uploaded file \"train_clean_male.wav\" with length 2522886 bytes\n",
            "User uploaded file \"train_dirty_male.wav\" with length 2522898 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "emfKplidbdDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
        "S_inp=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
        "X_inp=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "sx1, sr=librosa.load('test_x_01.wav', sr=None)\n",
        "test1 = librosa.stft(sx1, n_fft=1024, hop_length=512)\n",
        "sx2, sr=librosa.load('test_x_02.wav', sr=None)\n",
        "test2 = librosa.stft(sx2, n_fft=1024, hop_length=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjlfwChB9lDx",
        "colab_type": "code",
        "outputId": "fd13b24b-ea04-4477-af8a-c8b8bee72276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "S_inp.shape\n",
        "X_inp.shape\n",
        "test1.shape\n",
        "test2.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 2459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 2459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 380)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "l1rVDQg8LXVD",
        "colab_type": "code",
        "outputId": "b5724ff5-505f-4cc3-eaa4-14df76861db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Getting magnitudes as S and X are complex valued\n",
        "\n",
        "S_mod = np.transpose(np.abs(S_inp))\n",
        "X_mod = np.transpose(np.abs(X_inp))\n",
        "test1_mod = np.transpose(np.abs(test1))\n",
        "test2_mod = np.transpose(np.abs(test2))\n",
        "\n",
        "S_mod.shape\n",
        "X_mod.shape\n",
        "test1_mod.shape\n",
        "test2_mod.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "oREAligBLcdF",
        "colab_type": "code",
        "outputId": "ac99f58a-3347-4c9c-ddca-1f8ae84ccb18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "#1D CNN Architecture\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 513], name=\"X\")\n",
        "y = tf.placeholder(tf.float32, [None, 513], name=\"y\")\n",
        "dropout_var = tf.placeholder(\"float\")\n",
        "\n",
        "def cnn1d_neural_net(X, dp):\n",
        "    #Reshape input for CNN \n",
        "    X_cnn = tf.reshape(X, [-1,513,1])\n",
        "    #Convolution Layer 1\n",
        "    conv1 = tf.layers.conv1d(\n",
        "            inputs=X_cnn,\n",
        "            filters=32,\n",
        "            strides = 1,\n",
        "            kernel_size=16,\n",
        "            padding=\"same\",\n",
        "            activation=tf.nn.relu)\n",
        "    #Pooling Layer 1\n",
        "    pool1 = tf.layers.max_pooling1d(\n",
        "            inputs=conv1,\n",
        "            pool_size=2,\n",
        "            strides=2,\n",
        "            padding=\"same\")\n",
        "    #Convolution Layer 2\n",
        "    conv2 = tf.layers.conv1d(\n",
        "            inputs=pool1,\n",
        "            filters=32,\n",
        "            strides=1,\n",
        "            kernel_size=8,\n",
        "            padding=\"same\",\n",
        "            activation=tf.nn.relu)\n",
        "    #Pooling Layer 2\n",
        "    pool2 = tf.layers.max_pooling1d(\n",
        "            inputs=conv2,\n",
        "            pool_size=2,\n",
        "            strides=2)\n",
        "    #Flatten layer\n",
        "    pool2_flat = tf.layers.flatten(pool2)\n",
        "    \n",
        "    #Fully connected layers\n",
        "    layer1 = tf.layers.dense(\n",
        "                    inputs=pool2_flat,\n",
        "                    units=1024,\n",
        "                    activation=tf.nn.relu)\n",
        "    \n",
        "    dropout = tf.layers.dropout(\n",
        "            inputs=layer1,\n",
        "            rate=dp)\n",
        "    \n",
        "    output = tf.layers.dense(\n",
        "            inputs=dropout,\n",
        "            units=513,\n",
        "            activation=tf.nn.relu)\n",
        "\n",
        "    return (output)\n",
        "\n",
        "#Output \n",
        "output = cnn1d_neural_net(X, dropout_var)\n",
        "\n",
        "#Optimization\n",
        "cost = tf.reduce_mean(tf.losses.mean_squared_error(output, y)) \n",
        "train_optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "#Initializer\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-7aeee8cdec4d>:16: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv1d instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-10-7aeee8cdec4d>:22: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling1d instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-7aeee8cdec4d>:37: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-7aeee8cdec4d>:43: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-7aeee8cdec4d>:47: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DD4Ykziag_Vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function to calculate SNR\n",
        "\n",
        "def SNR_function(s, s_pred):\n",
        "    \n",
        "    nlen = min(len(s), len(s_pred))\n",
        "    SNR = 10*math.log10((np.sum(s[:nlen]**2))/(np.sum((s[:nlen] - s_pred[:nlen])**2)))\n",
        "    \n",
        "    return SNR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i6hj8SIFhDqj",
        "colab_type": "code",
        "outputId": "591926cb-a6ee-470d-c05c-49f53021705b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        }
      },
      "cell_type": "code",
      "source": [
        "#Running model on training speech signal dataset and checking (in batches)\n",
        "\n",
        "max_epochs = 1000\n",
        "batch_size = 128\n",
        "step = 5\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    avg_cost = 0.\n",
        "    random = np.arange(0, 2459, 128)\n",
        "    np.random.shuffle(random)\n",
        "    \n",
        "    for i in range(len(random)):\n",
        "        start = int(random[i])\n",
        "        end = int(start + batch_size)\n",
        "        b_x, b_y = np.array(X_mod[start:end,:]), np.array(S_mod[start:end])\n",
        "        data = {X: b_x, y: b_y, dropout_var : 0.2}\n",
        "        sess.run(train_optimizer, feed_dict=data)\n",
        "        avg_cost += sess.run(cost, feed_dict=data)\n",
        "     \n",
        "    avg_cost = avg_cost / len(random)\n",
        "        \n",
        "    if (epoch+1) % step == 0:\n",
        "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, max_epochs, avg_cost))\n",
        "        data = {X: b_x, y: b_y, dropout_var : 0.2}\n",
        "        train_output = sess.run(output, feed_dict=data)\n",
        "        \n",
        "        data = {X: X_mod, y: S_mod, dropout_var : 0.2}\n",
        "        full_train_output = sess.run(output, feed_dict=data)\n",
        "        \n",
        "print (\"=========================Model Optimization Complete============================\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 004/1000 cost: 0.010809428\n",
            "Epoch: 009/1000 cost: 0.006042133\n",
            "Epoch: 014/1000 cost: 0.006882394\n",
            "Epoch: 019/1000 cost: 0.003691017\n",
            "Epoch: 024/1000 cost: 0.003365514\n",
            "Epoch: 029/1000 cost: 0.003150398\n",
            "Epoch: 034/1000 cost: 0.002428060\n",
            "Epoch: 039/1000 cost: 0.002408685\n",
            "Epoch: 044/1000 cost: 0.002232445\n",
            "Epoch: 049/1000 cost: 0.003446339\n",
            "Epoch: 054/1000 cost: 0.002059321\n",
            "Epoch: 059/1000 cost: 0.001743725\n",
            "Epoch: 064/1000 cost: 0.003030069\n",
            "Epoch: 069/1000 cost: 0.004698553\n",
            "Epoch: 074/1000 cost: 0.001734368\n",
            "Epoch: 079/1000 cost: 0.001449856\n",
            "Epoch: 084/1000 cost: 0.001238381\n",
            "Epoch: 089/1000 cost: 0.001124857\n",
            "Epoch: 094/1000 cost: 0.001075878\n",
            "Epoch: 099/1000 cost: 0.001124738\n",
            "Epoch: 104/1000 cost: 0.001097991\n",
            "Epoch: 109/1000 cost: 0.003058501\n",
            "Epoch: 114/1000 cost: 0.001441706\n",
            "Epoch: 119/1000 cost: 0.001655763\n",
            "Epoch: 124/1000 cost: 0.003858744\n",
            "Epoch: 129/1000 cost: 0.001033761\n",
            "Epoch: 134/1000 cost: 0.001081006\n",
            "Epoch: 139/1000 cost: 0.000895004\n",
            "Epoch: 144/1000 cost: 0.000728444\n",
            "Epoch: 149/1000 cost: 0.000785352\n",
            "Epoch: 154/1000 cost: 0.000821100\n",
            "Epoch: 159/1000 cost: 0.001449157\n",
            "Epoch: 164/1000 cost: 0.000918918\n",
            "Epoch: 169/1000 cost: 0.000969306\n",
            "Epoch: 174/1000 cost: 0.001660239\n",
            "Epoch: 179/1000 cost: 0.002928811\n",
            "Epoch: 184/1000 cost: 0.001323653\n",
            "Epoch: 189/1000 cost: 0.000809113\n",
            "Epoch: 194/1000 cost: 0.000674368\n",
            "Epoch: 199/1000 cost: 0.000656134\n",
            "Epoch: 204/1000 cost: 0.000786097\n",
            "Epoch: 209/1000 cost: 0.000715238\n",
            "Epoch: 214/1000 cost: 0.001297009\n",
            "Epoch: 219/1000 cost: 0.001363451\n",
            "Epoch: 224/1000 cost: 0.000775330\n",
            "Epoch: 229/1000 cost: 0.000625583\n",
            "Epoch: 234/1000 cost: 0.000576210\n",
            "Epoch: 239/1000 cost: 0.000668890\n",
            "Epoch: 244/1000 cost: 0.002740830\n",
            "Epoch: 249/1000 cost: 0.001164142\n",
            "Epoch: 254/1000 cost: 0.000740877\n",
            "Epoch: 259/1000 cost: 0.001843549\n",
            "Epoch: 264/1000 cost: 0.001230586\n",
            "Epoch: 269/1000 cost: 0.000682219\n",
            "Epoch: 274/1000 cost: 0.000486454\n",
            "Epoch: 279/1000 cost: 0.000436361\n",
            "Epoch: 284/1000 cost: 0.000454026\n",
            "Epoch: 289/1000 cost: 0.000637596\n",
            "Epoch: 294/1000 cost: 0.000719003\n",
            "Epoch: 299/1000 cost: 0.000561920\n",
            "Epoch: 304/1000 cost: 0.000617085\n",
            "Epoch: 309/1000 cost: 0.000756659\n",
            "Epoch: 314/1000 cost: 0.000440575\n",
            "Epoch: 319/1000 cost: 0.000403482\n",
            "Epoch: 324/1000 cost: 0.000366433\n",
            "Epoch: 329/1000 cost: 0.000402764\n",
            "Epoch: 334/1000 cost: 0.000647392\n",
            "Epoch: 339/1000 cost: 0.001095225\n",
            "Epoch: 344/1000 cost: 0.001020903\n",
            "Epoch: 349/1000 cost: 0.000966525\n",
            "Epoch: 354/1000 cost: 0.000380038\n",
            "Epoch: 359/1000 cost: 0.000343539\n",
            "Epoch: 364/1000 cost: 0.000338193\n",
            "Epoch: 369/1000 cost: 0.000320475\n",
            "Epoch: 374/1000 cost: 0.000447057\n",
            "Epoch: 379/1000 cost: 0.002283805\n",
            "Epoch: 384/1000 cost: 0.000587741\n",
            "Epoch: 389/1000 cost: 0.000672335\n",
            "Epoch: 394/1000 cost: 0.000545804\n",
            "Epoch: 399/1000 cost: 0.000396883\n",
            "Epoch: 404/1000 cost: 0.000301586\n",
            "Epoch: 409/1000 cost: 0.000346665\n",
            "Epoch: 414/1000 cost: 0.000856809\n",
            "Epoch: 419/1000 cost: 0.000338068\n",
            "Epoch: 424/1000 cost: 0.000609270\n",
            "Epoch: 429/1000 cost: 0.000413672\n",
            "Epoch: 434/1000 cost: 0.000387228\n",
            "Epoch: 439/1000 cost: 0.001811485\n",
            "Epoch: 444/1000 cost: 0.000587497\n",
            "Epoch: 449/1000 cost: 0.000497702\n",
            "Epoch: 454/1000 cost: 0.000470724\n",
            "Epoch: 459/1000 cost: 0.000402912\n",
            "Epoch: 464/1000 cost: 0.000295461\n",
            "Epoch: 469/1000 cost: 0.000274841\n",
            "Epoch: 474/1000 cost: 0.000322827\n",
            "Epoch: 479/1000 cost: 0.000313709\n",
            "Epoch: 484/1000 cost: 0.000320486\n",
            "Epoch: 489/1000 cost: 0.000322629\n",
            "Epoch: 494/1000 cost: 0.002470622\n",
            "Epoch: 499/1000 cost: 0.000499997\n",
            "Epoch: 504/1000 cost: 0.000313313\n",
            "Epoch: 509/1000 cost: 0.000280697\n",
            "Epoch: 514/1000 cost: 0.000276445\n",
            "Epoch: 519/1000 cost: 0.000375899\n",
            "Epoch: 524/1000 cost: 0.000597002\n",
            "Epoch: 529/1000 cost: 0.000505604\n",
            "Epoch: 534/1000 cost: 0.000777966\n",
            "Epoch: 539/1000 cost: 0.000586397\n",
            "Epoch: 544/1000 cost: 0.000417713\n",
            "Epoch: 549/1000 cost: 0.000276929\n",
            "Epoch: 554/1000 cost: 0.000254634\n",
            "Epoch: 559/1000 cost: 0.000261890\n",
            "Epoch: 564/1000 cost: 0.000307279\n",
            "Epoch: 569/1000 cost: 0.000313442\n",
            "Epoch: 574/1000 cost: 0.000372447\n",
            "Epoch: 579/1000 cost: 0.001146729\n",
            "Epoch: 584/1000 cost: 0.000826623\n",
            "Epoch: 589/1000 cost: 0.000494373\n",
            "Epoch: 594/1000 cost: 0.000266445\n",
            "Epoch: 599/1000 cost: 0.000242745\n",
            "Epoch: 604/1000 cost: 0.000266212\n",
            "Epoch: 609/1000 cost: 0.000252082\n",
            "Epoch: 614/1000 cost: 0.000247684\n",
            "Epoch: 619/1000 cost: 0.000226008\n",
            "Epoch: 624/1000 cost: 0.000288162\n",
            "Epoch: 629/1000 cost: 0.000440824\n",
            "Epoch: 634/1000 cost: 0.000561247\n",
            "Epoch: 639/1000 cost: 0.000433060\n",
            "Epoch: 644/1000 cost: 0.000605190\n",
            "Epoch: 649/1000 cost: 0.000454318\n",
            "Epoch: 654/1000 cost: 0.000431150\n",
            "Epoch: 659/1000 cost: 0.000699506\n",
            "Epoch: 664/1000 cost: 0.000689118\n",
            "Epoch: 669/1000 cost: 0.000476116\n",
            "Epoch: 674/1000 cost: 0.000240416\n",
            "Epoch: 679/1000 cost: 0.000218106\n",
            "Epoch: 684/1000 cost: 0.000219964\n",
            "Epoch: 689/1000 cost: 0.000245824\n",
            "Epoch: 694/1000 cost: 0.000269557\n",
            "Epoch: 699/1000 cost: 0.000222742\n",
            "Epoch: 704/1000 cost: 0.000301272\n",
            "Epoch: 709/1000 cost: 0.000327131\n",
            "Epoch: 714/1000 cost: 0.000271110\n",
            "Epoch: 719/1000 cost: 0.000271409\n",
            "Epoch: 724/1000 cost: 0.000622588\n",
            "Epoch: 729/1000 cost: 0.001121580\n",
            "Epoch: 734/1000 cost: 0.000410670\n",
            "Epoch: 739/1000 cost: 0.000438005\n",
            "Epoch: 744/1000 cost: 0.000237026\n",
            "Epoch: 749/1000 cost: 0.000215906\n",
            "Epoch: 754/1000 cost: 0.000216987\n",
            "Epoch: 759/1000 cost: 0.000221708\n",
            "Epoch: 764/1000 cost: 0.000249288\n",
            "Epoch: 769/1000 cost: 0.000547694\n",
            "Epoch: 774/1000 cost: 0.000414493\n",
            "Epoch: 779/1000 cost: 0.001474911\n",
            "Epoch: 784/1000 cost: 0.000267851\n",
            "Epoch: 789/1000 cost: 0.000216910\n",
            "Epoch: 794/1000 cost: 0.000198106\n",
            "Epoch: 799/1000 cost: 0.000195372\n",
            "Epoch: 804/1000 cost: 0.000205615\n",
            "Epoch: 809/1000 cost: 0.000231804\n",
            "Epoch: 814/1000 cost: 0.000280146\n",
            "Epoch: 819/1000 cost: 0.000813547\n",
            "Epoch: 824/1000 cost: 0.000494545\n",
            "Epoch: 829/1000 cost: 0.000247538\n",
            "Epoch: 834/1000 cost: 0.000204994\n",
            "Epoch: 839/1000 cost: 0.000194205\n",
            "Epoch: 844/1000 cost: 0.000270248\n",
            "Epoch: 849/1000 cost: 0.000302811\n",
            "Epoch: 854/1000 cost: 0.000420358\n",
            "Epoch: 859/1000 cost: 0.000316423\n",
            "Epoch: 864/1000 cost: 0.000276953\n",
            "Epoch: 869/1000 cost: 0.000228775\n",
            "Epoch: 874/1000 cost: 0.000206489\n",
            "Epoch: 879/1000 cost: 0.000394044\n",
            "Epoch: 884/1000 cost: 0.000710950\n",
            "Epoch: 889/1000 cost: 0.000490461\n",
            "Epoch: 894/1000 cost: 0.000266520\n",
            "Epoch: 899/1000 cost: 0.000202564\n",
            "Epoch: 904/1000 cost: 0.000185251\n",
            "Epoch: 909/1000 cost: 0.000180439\n",
            "Epoch: 914/1000 cost: 0.000186984\n",
            "Epoch: 919/1000 cost: 0.000189198\n",
            "Epoch: 924/1000 cost: 0.000264972\n",
            "Epoch: 929/1000 cost: 0.000285053\n",
            "Epoch: 934/1000 cost: 0.000252007\n",
            "Epoch: 939/1000 cost: 0.000297332\n",
            "Epoch: 944/1000 cost: 0.000943083\n",
            "Epoch: 949/1000 cost: 0.000321832\n",
            "Epoch: 954/1000 cost: 0.000199370\n",
            "Epoch: 959/1000 cost: 0.000186502\n",
            "Epoch: 964/1000 cost: 0.000274963\n",
            "Epoch: 969/1000 cost: 0.000477660\n",
            "Epoch: 974/1000 cost: 0.000253722\n",
            "Epoch: 979/1000 cost: 0.000216294\n",
            "Epoch: 984/1000 cost: 0.000200782\n",
            "Epoch: 989/1000 cost: 0.000237325\n",
            "Epoch: 994/1000 cost: 0.000298477\n",
            "Epoch: 999/1000 cost: 0.000338872\n",
            "=========================Model Optimization Complete============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2jARHHz8l6GP",
        "colab_type": "code",
        "outputId": "6b8f6a75-97e9-4c72-a006-1614cc56c4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#SNR Calculation on whole dataset\n",
        "s_hat = (X_inp / np.abs(X_inp)) * np.transpose(full_train_output)\n",
        "s_pred = librosa.istft(s_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "s.shape\n",
        "s_pred.shape\n",
        "\n",
        "print (SNR_function(s,s_pred))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258899,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258496,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "text": [
            "19.358574382825605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gdTWHpydmGD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "librosa.output.write_wav('train_recovered_1dcnn.wav', s_pred, sr)\n",
        "\n",
        "files.download('train_recovered_1dcnn.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ValHZv9qmVnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#On test signal 1\n",
        "\n",
        "data = {X: test1_mod, y : S_mod, dropout_var : 0.2}\n",
        "test1_output = sess.run(output, feed_dict=data)\n",
        "\n",
        "test1_hat = (test1 / np.abs(test1)) * np.transpose(test1_output)\n",
        "test1_pred = librosa.istft(test1_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "\n",
        "librosa.output.write_wav('test_s_01_recons_1dcnn.wav', test1_pred, sr)\n",
        "\n",
        "files.download('test_s_01_recons_1dcnn.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCuMhr6Umk4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#On test signal 2\n",
        "\n",
        "data = {X: test2_mod, y : S_mod, dropout_var : 0.2}\n",
        "test2_output = sess.run(output, feed_dict=data)\n",
        "\n",
        "test2_hat = (test2 / np.abs(test2)) * np.transpose(test2_output)\n",
        "test2_pred = librosa.istft(test2_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "\n",
        "librosa.output.write_wav('test_s_02_recons_1dcnn.wav', test2_pred, sr)\n",
        "\n",
        "files.download('test_s_02_recons_1dcnn.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}