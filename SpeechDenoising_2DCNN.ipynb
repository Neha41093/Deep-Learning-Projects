{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_SpeechDenoising_2DCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0xU6VZojm6l6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Speech Denoising using 2D CNN**"
      ]
    },
    {
      "metadata": {
        "id": "gIAb0HgIm0T_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "19f3a546-d49e-41ef-816f-5db41600478e"
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa # in colab, you'll need to install this\n",
        "import librosa"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.27.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C5ma4x_PnGtp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "from __future__ import print_function, absolute_import, division\n",
        "from ipywidgets import interact, interactive, fixed\n",
        "import ipywidgets as widgets\n",
        "from math import ceil\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNB922lyoRc3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqJ7pM3soVFg",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "c7a23204-0ac6-4092-cd2c-5c49c9bed716"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a5373585-7f20-4afc-b19e-e14ead07fca9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a5373585-7f20-4afc-b19e-e14ead07fca9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_x_01.wav to test_x_01.wav\n",
            "Saving test_x_02.wav to test_x_02.wav\n",
            "Saving train_clean_male.wav to train_clean_male.wav\n",
            "Saving train_dirty_male.wav to train_dirty_male.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EShSLdTiohx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "1e129ece-a9a2-41c6-8a08-586deb9e7fab"
      },
      "cell_type": "code",
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"test_x_01.wav\" with length 145284 bytes\n",
            "User uploaded file \"test_x_02.wav\" with length 388752 bytes\n",
            "User uploaded file \"train_clean_male.wav\" with length 2522886 bytes\n",
            "User uploaded file \"train_dirty_male.wav\" with length 2522898 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MRqcbh96orbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
        "S_inp=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
        "X_inp=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "sx1, sr=librosa.load('test_x_01.wav', sr=None)\n",
        "test1 = librosa.stft(sx1, n_fft=1024, hop_length=512)\n",
        "sx2, sr=librosa.load('test_x_02.wav', sr=None)\n",
        "test2 = librosa.stft(sx2, n_fft=1024, hop_length=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-uKS4YZCqebK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3fa0222-7271-4a73-c152-7eef255d6757"
      },
      "cell_type": "code",
      "source": [
        "S_inp.shape\n",
        "X_inp.shape\n",
        "test1.shape\n",
        "test2.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 2459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 2459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 380)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "33WNLrAYqhfx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cde5734e-f284-4a0b-96dc-1f283576b48b"
      },
      "cell_type": "code",
      "source": [
        "#Getting magnitudes as S and X are complex valued\n",
        "\n",
        "S_mod = np.transpose(np.abs(S_inp))\n",
        "X_mod = np.transpose(np.abs(X_inp))\n",
        "test1_mod = np.transpose(np.abs(test1))\n",
        "test2_mod = np.transpose(np.abs(test2))\n",
        "\n",
        "S_mod.shape\n",
        "X_mod.shape\n",
        "test1_mod.shape\n",
        "test2_mod.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "K5h3iIk7qlpC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d33e6039-faa1-4473-ecd3-cb1e0860144b"
      },
      "cell_type": "code",
      "source": [
        "#2D CNN Architecture\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 20, 513], name=\"X\")\n",
        "y = tf.placeholder(tf.float32, [None, 513], name=\"y\")\n",
        "dropout_var = tf.placeholder(\"float\")\n",
        "\n",
        "def cnn2d_neural_net(X, dp):\n",
        "    #Reshape input for CNN \n",
        "    X_cnn = tf.reshape(X, (-1, 20, 513, 1))\n",
        "\n",
        "    #Convolution Layer 1\n",
        "    conv1 = tf.layers.conv2d(\n",
        "            inputs=X_cnn,\n",
        "            filters=32,\n",
        "            kernel_size=[4,4],\n",
        "            padding=\"same\",\n",
        "            activation=tf.nn.relu)\n",
        "    #Pooling Layer 1\n",
        "    pool1 = tf.layers.max_pooling2d(\n",
        "            inputs=conv1,\n",
        "            pool_size=[2,2],\n",
        "            strides=[2,2],\n",
        "            padding=\"same\")\n",
        "    #Convolution Layer 2\n",
        "    conv2 = tf.layers.conv2d(\n",
        "            inputs=pool1,\n",
        "            filters=32,\n",
        "            kernel_size=[2,2],\n",
        "            padding=\"same\",\n",
        "            activation=tf.nn.relu)\n",
        "    #Pooling Layer 2\n",
        "    pool2 = tf.layers.max_pooling2d(\n",
        "            inputs=conv2,\n",
        "            pool_size=[2,2],\n",
        "            strides=[2,2])\n",
        "    #Flatten layer\n",
        "    pool2_flat = tf.layers.flatten(pool2)\n",
        "    \n",
        "    #Fully connected layers\n",
        "    layer1 = tf.layers.dense(\n",
        "                    inputs=pool2_flat,\n",
        "                    units=1024,\n",
        "                    activation=tf.nn.relu)\n",
        "    \n",
        "    dropout = tf.layers.dropout(\n",
        "            inputs=layer1,\n",
        "            rate=dp)\n",
        "    \n",
        "    output = tf.layers.dense(\n",
        "            inputs=dropout,\n",
        "            units=513,\n",
        "            activation=tf.nn.relu)\n",
        "\n",
        "    return (output)\n",
        "\n",
        "#Output \n",
        "output = cnn2d_neural_net(X, dropout_var)\n",
        "\n",
        "#Optimization\n",
        "cost = tf.reduce_mean(tf.losses.mean_squared_error(output, y)) \n",
        "train_optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "#Initializer\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-9ee4bb894d71>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-9-9ee4bb894d71>:22: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-9-9ee4bb894d71>:36: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-9-9ee4bb894d71>:42: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-9-9ee4bb894d71>:46: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMmO8A4-zlew",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function to calculate SNR\n",
        "\n",
        "def SNR_function(s, s_pred):\n",
        "    \n",
        "    nlen = min(len(s), len(s_pred))\n",
        "    SNR = 10*math.log10((np.sum(s[:nlen]**2))/(np.sum((s[:nlen] - s_pred[:nlen])**2)))\n",
        "    \n",
        "    return SNR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzsTvBsmzqPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        },
        "outputId": "1f202e49-d8e2-43b2-ccb1-99ad00c2ace4"
      },
      "cell_type": "code",
      "source": [
        "#Running model on training speech signal dataset and checking (in batches)\n",
        "\n",
        "max_epochs = 1000\n",
        "batch_size = 128\n",
        "step = 5\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "X_shifted = np.array([np.reshape(X_mod[i:i+20],(20,513)) for i in range(2440)])\n",
        "y_shifted = S_mod[19:,:]\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    avg_cost = 0.\n",
        "    random = np.arange(0, 2440, 128)\n",
        "    np.random.shuffle(random)\n",
        "    \n",
        "    for i in range(len(random)):\n",
        "        start = int(random[i])\n",
        "        end = int(start + batch_size)\n",
        "        b_x, b_y = np.array(X_shifted[start:end,:,:]), np.array(y_shifted[start:end])\n",
        "        data = {X: b_x, y: b_y, dropout_var : 0.2}\n",
        "        sess.run(train_optimizer, feed_dict=data)\n",
        "        avg_cost += sess.run(cost, feed_dict=data)\n",
        "     \n",
        "    avg_cost = avg_cost / len(random)\n",
        "        \n",
        "    if (epoch+1) % step == 0:\n",
        "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, max_epochs, avg_cost))\n",
        "        data = {X: b_x, y: b_y, dropout_var : 0.2}\n",
        "        train_output = sess.run(output, feed_dict=data)\n",
        "        \n",
        "        data = {X: X_shifted, y: y_shifted, dropout_var : 0.2}\n",
        "        full_train_output = sess.run(output, feed_dict=data)\n",
        "        \n",
        "print (\"=========================Model Optimization Complete============================\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 004/1000 cost: 0.029571954\n",
            "Epoch: 009/1000 cost: 0.011974132\n",
            "Epoch: 014/1000 cost: 0.007820888\n",
            "Epoch: 019/1000 cost: 0.005970108\n",
            "Epoch: 024/1000 cost: 0.004620082\n",
            "Epoch: 029/1000 cost: 0.005082565\n",
            "Epoch: 034/1000 cost: 0.004294476\n",
            "Epoch: 039/1000 cost: 0.005770985\n",
            "Epoch: 044/1000 cost: 0.003335274\n",
            "Epoch: 049/1000 cost: 0.003208236\n",
            "Epoch: 054/1000 cost: 0.002570640\n",
            "Epoch: 059/1000 cost: 0.002267038\n",
            "Epoch: 064/1000 cost: 0.002317241\n",
            "Epoch: 069/1000 cost: 0.002525717\n",
            "Epoch: 074/1000 cost: 0.002285717\n",
            "Epoch: 079/1000 cost: 0.002087444\n",
            "Epoch: 084/1000 cost: 0.004194754\n",
            "Epoch: 089/1000 cost: 0.002416093\n",
            "Epoch: 094/1000 cost: 0.001916490\n",
            "Epoch: 099/1000 cost: 0.001633182\n",
            "Epoch: 104/1000 cost: 0.001814092\n",
            "Epoch: 109/1000 cost: 0.001721575\n",
            "Epoch: 114/1000 cost: 0.001682994\n",
            "Epoch: 119/1000 cost: 0.001417158\n",
            "Epoch: 124/1000 cost: 0.001451881\n",
            "Epoch: 129/1000 cost: 0.002791699\n",
            "Epoch: 134/1000 cost: 0.002201653\n",
            "Epoch: 139/1000 cost: 0.001549214\n",
            "Epoch: 144/1000 cost: 0.001232424\n",
            "Epoch: 149/1000 cost: 0.001208119\n",
            "Epoch: 154/1000 cost: 0.001428106\n",
            "Epoch: 159/1000 cost: 0.001672771\n",
            "Epoch: 164/1000 cost: 0.001240093\n",
            "Epoch: 169/1000 cost: 0.001138543\n",
            "Epoch: 174/1000 cost: 0.001384931\n",
            "Epoch: 179/1000 cost: 0.001211891\n",
            "Epoch: 184/1000 cost: 0.001128156\n",
            "Epoch: 189/1000 cost: 0.001156369\n",
            "Epoch: 194/1000 cost: 0.001076378\n",
            "Epoch: 199/1000 cost: 0.001284997\n",
            "Epoch: 204/1000 cost: 0.002332619\n",
            "Epoch: 209/1000 cost: 0.001336620\n",
            "Epoch: 214/1000 cost: 0.001597020\n",
            "Epoch: 219/1000 cost: 0.001599142\n",
            "Epoch: 224/1000 cost: 0.001505135\n",
            "Epoch: 229/1000 cost: 0.000995404\n",
            "Epoch: 234/1000 cost: 0.000862209\n",
            "Epoch: 239/1000 cost: 0.000837613\n",
            "Epoch: 244/1000 cost: 0.000855174\n",
            "Epoch: 249/1000 cost: 0.000827748\n",
            "Epoch: 254/1000 cost: 0.000763135\n",
            "Epoch: 259/1000 cost: 0.000885229\n",
            "Epoch: 264/1000 cost: 0.000885481\n",
            "Epoch: 269/1000 cost: 0.000999182\n",
            "Epoch: 274/1000 cost: 0.001998058\n",
            "Epoch: 279/1000 cost: 0.001238417\n",
            "Epoch: 284/1000 cost: 0.001115518\n",
            "Epoch: 289/1000 cost: 0.000871484\n",
            "Epoch: 294/1000 cost: 0.000777051\n",
            "Epoch: 299/1000 cost: 0.000702872\n",
            "Epoch: 304/1000 cost: 0.000653246\n",
            "Epoch: 309/1000 cost: 0.001056886\n",
            "Epoch: 314/1000 cost: 0.000815928\n",
            "Epoch: 319/1000 cost: 0.001171028\n",
            "Epoch: 324/1000 cost: 0.001482597\n",
            "Epoch: 329/1000 cost: 0.000851608\n",
            "Epoch: 334/1000 cost: 0.000773343\n",
            "Epoch: 339/1000 cost: 0.000611696\n",
            "Epoch: 344/1000 cost: 0.000589302\n",
            "Epoch: 349/1000 cost: 0.000595849\n",
            "Epoch: 354/1000 cost: 0.001135333\n",
            "Epoch: 359/1000 cost: 0.001317663\n",
            "Epoch: 364/1000 cost: 0.000871169\n",
            "Epoch: 369/1000 cost: 0.000708230\n",
            "Epoch: 374/1000 cost: 0.000596745\n",
            "Epoch: 379/1000 cost: 0.000849386\n",
            "Epoch: 384/1000 cost: 0.001450056\n",
            "Epoch: 389/1000 cost: 0.001003076\n",
            "Epoch: 394/1000 cost: 0.000707479\n",
            "Epoch: 399/1000 cost: 0.000577554\n",
            "Epoch: 404/1000 cost: 0.000577226\n",
            "Epoch: 409/1000 cost: 0.000561231\n",
            "Epoch: 414/1000 cost: 0.000816168\n",
            "Epoch: 419/1000 cost: 0.001140026\n",
            "Epoch: 424/1000 cost: 0.000666224\n",
            "Epoch: 429/1000 cost: 0.000791927\n",
            "Epoch: 434/1000 cost: 0.000631799\n",
            "Epoch: 439/1000 cost: 0.000697615\n",
            "Epoch: 444/1000 cost: 0.000726869\n",
            "Epoch: 449/1000 cost: 0.000957006\n",
            "Epoch: 454/1000 cost: 0.001371723\n",
            "Epoch: 459/1000 cost: 0.000739361\n",
            "Epoch: 464/1000 cost: 0.000712169\n",
            "Epoch: 469/1000 cost: 0.000518713\n",
            "Epoch: 474/1000 cost: 0.000513070\n",
            "Epoch: 479/1000 cost: 0.000463015\n",
            "Epoch: 484/1000 cost: 0.000517638\n",
            "Epoch: 489/1000 cost: 0.000548613\n",
            "Epoch: 494/1000 cost: 0.000671800\n",
            "Epoch: 499/1000 cost: 0.000571215\n",
            "Epoch: 504/1000 cost: 0.000842595\n",
            "Epoch: 509/1000 cost: 0.000830742\n",
            "Epoch: 514/1000 cost: 0.000605674\n",
            "Epoch: 519/1000 cost: 0.000559425\n",
            "Epoch: 524/1000 cost: 0.000573678\n",
            "Epoch: 529/1000 cost: 0.000807985\n",
            "Epoch: 534/1000 cost: 0.000626271\n",
            "Epoch: 539/1000 cost: 0.000773432\n",
            "Epoch: 544/1000 cost: 0.001115056\n",
            "Epoch: 549/1000 cost: 0.001014441\n",
            "Epoch: 554/1000 cost: 0.000741785\n",
            "Epoch: 559/1000 cost: 0.000519124\n",
            "Epoch: 564/1000 cost: 0.000451431\n",
            "Epoch: 569/1000 cost: 0.000433861\n",
            "Epoch: 574/1000 cost: 0.000443042\n",
            "Epoch: 579/1000 cost: 0.000434399\n",
            "Epoch: 584/1000 cost: 0.000414861\n",
            "Epoch: 589/1000 cost: 0.000419523\n",
            "Epoch: 594/1000 cost: 0.000438051\n",
            "Epoch: 599/1000 cost: 0.000446673\n",
            "Epoch: 604/1000 cost: 0.000553870\n",
            "Epoch: 609/1000 cost: 0.000574363\n",
            "Epoch: 614/1000 cost: 0.000735667\n",
            "Epoch: 619/1000 cost: 0.000754734\n",
            "Epoch: 624/1000 cost: 0.000730285\n",
            "Epoch: 629/1000 cost: 0.001322448\n",
            "Epoch: 634/1000 cost: 0.000728525\n",
            "Epoch: 639/1000 cost: 0.000541546\n",
            "Epoch: 644/1000 cost: 0.000428662\n",
            "Epoch: 649/1000 cost: 0.000587099\n",
            "Epoch: 654/1000 cost: 0.000845469\n",
            "Epoch: 659/1000 cost: 0.000481903\n",
            "Epoch: 664/1000 cost: 0.000446363\n",
            "Epoch: 669/1000 cost: 0.000474831\n",
            "Epoch: 674/1000 cost: 0.000814834\n",
            "Epoch: 679/1000 cost: 0.000568315\n",
            "Epoch: 684/1000 cost: 0.000479871\n",
            "Epoch: 689/1000 cost: 0.000418137\n",
            "Epoch: 694/1000 cost: 0.000415794\n",
            "Epoch: 699/1000 cost: 0.000425768\n",
            "Epoch: 704/1000 cost: 0.000426498\n",
            "Epoch: 709/1000 cost: 0.000592601\n",
            "Epoch: 714/1000 cost: 0.001408176\n",
            "Epoch: 719/1000 cost: 0.000591238\n",
            "Epoch: 724/1000 cost: 0.000425246\n",
            "Epoch: 729/1000 cost: 0.000401060\n",
            "Epoch: 734/1000 cost: 0.000450279\n",
            "Epoch: 739/1000 cost: 0.000544775\n",
            "Epoch: 744/1000 cost: 0.000433780\n",
            "Epoch: 749/1000 cost: 0.000851198\n",
            "Epoch: 754/1000 cost: 0.001259905\n",
            "Epoch: 759/1000 cost: 0.001500018\n",
            "Epoch: 764/1000 cost: 0.000569172\n",
            "Epoch: 769/1000 cost: 0.000441659\n",
            "Epoch: 774/1000 cost: 0.000379052\n",
            "Epoch: 779/1000 cost: 0.000369328\n",
            "Epoch: 784/1000 cost: 0.000409712\n",
            "Epoch: 789/1000 cost: 0.000381828\n",
            "Epoch: 794/1000 cost: 0.000391390\n",
            "Epoch: 799/1000 cost: 0.000469838\n",
            "Epoch: 804/1000 cost: 0.000549710\n",
            "Epoch: 809/1000 cost: 0.000428878\n",
            "Epoch: 814/1000 cost: 0.000485805\n",
            "Epoch: 819/1000 cost: 0.001065015\n",
            "Epoch: 824/1000 cost: 0.000906451\n",
            "Epoch: 829/1000 cost: 0.000492662\n",
            "Epoch: 834/1000 cost: 0.000390319\n",
            "Epoch: 839/1000 cost: 0.000375379\n",
            "Epoch: 844/1000 cost: 0.000373613\n",
            "Epoch: 849/1000 cost: 0.000368486\n",
            "Epoch: 854/1000 cost: 0.000357277\n",
            "Epoch: 859/1000 cost: 0.000362219\n",
            "Epoch: 864/1000 cost: 0.000366898\n",
            "Epoch: 869/1000 cost: 0.000459339\n",
            "Epoch: 874/1000 cost: 0.000695361\n",
            "Epoch: 879/1000 cost: 0.000725892\n",
            "Epoch: 884/1000 cost: 0.000465312\n",
            "Epoch: 889/1000 cost: 0.000400436\n",
            "Epoch: 894/1000 cost: 0.000789131\n",
            "Epoch: 899/1000 cost: 0.000897432\n",
            "Epoch: 904/1000 cost: 0.000407127\n",
            "Epoch: 909/1000 cost: 0.000370104\n",
            "Epoch: 914/1000 cost: 0.000356059\n",
            "Epoch: 919/1000 cost: 0.000353336\n",
            "Epoch: 924/1000 cost: 0.000351582\n",
            "Epoch: 929/1000 cost: 0.000357044\n",
            "Epoch: 934/1000 cost: 0.000387004\n",
            "Epoch: 939/1000 cost: 0.000481869\n",
            "Epoch: 944/1000 cost: 0.000491882\n",
            "Epoch: 949/1000 cost: 0.000948812\n",
            "Epoch: 954/1000 cost: 0.000642126\n",
            "Epoch: 959/1000 cost: 0.000442249\n",
            "Epoch: 964/1000 cost: 0.000371838\n",
            "Epoch: 969/1000 cost: 0.000366517\n",
            "Epoch: 974/1000 cost: 0.000369451\n",
            "Epoch: 979/1000 cost: 0.000468319\n",
            "Epoch: 984/1000 cost: 0.002461443\n",
            "Epoch: 989/1000 cost: 0.000515306\n",
            "Epoch: 994/1000 cost: 0.000374630\n",
            "Epoch: 999/1000 cost: 0.000346449\n",
            "=========================Model Optimization Complete============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m8JeREt8_JSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2c9ea427-3a35-4b53-ce6f-63bfca033099"
      },
      "cell_type": "code",
      "source": [
        "#Adding noise frames with small values\n",
        "\n",
        "full_train_output_pad = np.vstack((np.full((19,513),0.0000000000000000015), full_train_output))\n",
        "full_train_output_pad.shape\n",
        "print(full_train_output_pad)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "stream",
          "text": [
            "[[1.50000000e-18 1.50000000e-18 1.50000000e-18 ... 1.50000000e-18\n",
            "  1.50000000e-18 1.50000000e-18]\n",
            " [1.50000000e-18 1.50000000e-18 1.50000000e-18 ... 1.50000000e-18\n",
            "  1.50000000e-18 1.50000000e-18]\n",
            " [1.50000000e-18 1.50000000e-18 1.50000000e-18 ... 1.50000000e-18\n",
            "  1.50000000e-18 1.50000000e-18]\n",
            " ...\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 1.83241218e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mJWIJfRP5DQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80e988ba-2f9e-4d43-dc97-d6b85f8158d5"
      },
      "cell_type": "code",
      "source": [
        "#SNR Calculation on whole dataset\n",
        "\n",
        "s_hat = (X_inp / np.abs(X_inp)) * np.transpose(full_train_output_pad)\n",
        "s_pred = librosa.istft(s_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "s.shape\n",
        "s_pred.shape\n",
        "\n",
        "print (SNR_function(s,s_pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258899,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258496,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "17.486399235373355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hnYvB55FGeZf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "librosa.output.write_wav('train_recovered_2dcnn.wav', s_pred, sr)\n",
        "\n",
        "files.download('train_recovered_2dcnn.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gMarTzTgHPVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2f221cb-fca6-4099-df89-60bb536c918f"
      },
      "cell_type": "code",
      "source": [
        "#On test signal 1\n",
        "\n",
        "test1_shifted = np.array([np.reshape(test1_mod[i:i+20],(20,513)) for i in range(123)])\n",
        "\n",
        "data = {X: test1_shifted, y : y_shifted, dropout_var : 0.2}\n",
        "test1_output = sess.run(output, feed_dict=data)\n",
        "test1_output_pad = np.vstack((np.full((19,513),0.0000000000000000015), test1_output))\n",
        "test1_output_pad.shape\n",
        "\n",
        "test1_hat = (test1 / np.abs(test1)) * np.transpose(test1_output_pad)\n",
        "test1_pred = librosa.istft(test1_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "\n",
        "librosa.output.write_wav('test_s_01_recons_2dcnn.wav', test1_pred, sr)\n",
        "\n",
        "files.download('test_s_01_recons_2dcnn.wav')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "jVD8Tbg7IFXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98b51cfd-02f8-4fd2-be8c-04d1f47df6e1"
      },
      "cell_type": "code",
      "source": [
        "#On test signal 2\n",
        "\n",
        "test2_shifted = np.array([np.reshape(test2_mod[i:i+20],(20,513)) for i in range(361)])\n",
        "\n",
        "data = {X: test2_shifted, y : y_shifted, dropout_var : 0.2}\n",
        "test2_output = sess.run(output, feed_dict=data)\n",
        "test2_output_pad = np.vstack((np.full((19,513),0.0000000000000000015), test2_output))\n",
        "test2_output_pad.shape\n",
        "\n",
        "test2_hat = (test2 / np.abs(test2)) * np.transpose(test2_output_pad)\n",
        "test2_pred = librosa.istft(test2_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "\n",
        "librosa.output.write_wav('test_s_02_recons_2dcnn.wav', test2_pred, sr)\n",
        "\n",
        "files.download('test_s_02_recons_2dcnn.wav')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}