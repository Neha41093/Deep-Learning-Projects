{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1_SpeechDenoising_TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DL_Mb46f1vbv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Speech Denoising Question**"
      ]
    },
    {
      "metadata": {
        "id": "sayp811Z1kMu",
        "colab_type": "code",
        "outputId": "3faadbbb-639f-4075-ba22-780e144763cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa # in colab, you'll need to install this\n",
        "import librosa"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.27.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LVMFkk1y1-qp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed\n",
        "import ipywidgets as widgets\n",
        "from math import ceil\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYTMC89-2Dk1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3NRf8ls2uyj",
        "colab_type": "code",
        "outputId": "dc4148ba-e21a-4d67-a4a1-c10dbba8512e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-513e3498-c40a-4e2e-97fe-45ab67a61e1f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-513e3498-c40a-4e2e-97fe-45ab67a61e1f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_x_01.wav to test_x_01 (5).wav\n",
            "Saving test_x_02.wav to test_x_02 (5).wav\n",
            "Saving train_clean_male.wav to train_clean_male (5).wav\n",
            "Saving train_dirty_male.wav to train_dirty_male (5).wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNdAf-6v2_Pm",
        "colab_type": "code",
        "outputId": "2b8bc313-697d-4816-f233-80e210d561fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"test_x_01.wav\" with length 145284 bytes\n",
            "User uploaded file \"test_x_02.wav\" with length 388752 bytes\n",
            "User uploaded file \"train_clean_male.wav\" with length 2522886 bytes\n",
            "User uploaded file \"train_dirty_male.wav\" with length 2522898 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9whIAiFL16x0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
        "S_inp=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
        "X_inp=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "sx1, sr=librosa.load('test_x_01.wav', sr=None)\n",
        "test1 = librosa.stft(sx1, n_fft=1024, hop_length=512)\n",
        "sx2, sr=librosa.load('test_x_02.wav', sr=None)\n",
        "test2 = librosa.stft(sx2, n_fft=1024, hop_length=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1XOopS_3Isv",
        "colab_type": "code",
        "outputId": "bfe2f3f6-ed06-47bd-b8f7-8f5ac1c882df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "S_inp.shape\n",
        "X_inp.shape\n",
        "test1.shape\n",
        "test2.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 2459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 2459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 380)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "f3nwR9wK4Jd0",
        "colab_type": "code",
        "outputId": "92e9c20e-04d9-4645-efb1-f2846d2b8350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Getting magnitudes as S and X are complex valued\n",
        "\n",
        "S_mod = np.transpose(np.abs(S_inp))\n",
        "X_mod = np.transpose(np.abs(X_inp))\n",
        "test1_mod = np.transpose(np.abs(test1))\n",
        "test2_mod = np.transpose(np.abs(test2))\n",
        "\n",
        "S_mod.shape\n",
        "X_mod.shape\n",
        "test1_mod.shape\n",
        "test2_mod.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "XiEJ7e3MAD0c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Deep Neural Network for Speech Denoising**"
      ]
    },
    {
      "metadata": {
        "id": "5w-t7xAK4W3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training and running neural net\n",
        "\n",
        "#Weight Variable\n",
        "def weights(shape, name):\n",
        "    i = tf.contrib.layers.variance_scaling_initializer(factor=2.0 , mode='FAN_AVG',uniform=True, seed=None, dtype=tf.float32)\n",
        "    return tf.Variable(i(shape), name=name)\n",
        "\n",
        "#Bias Variable\n",
        "def bias(shape, name):\n",
        "    i = tf.contrib.layers.variance_scaling_initializer(factor=2.0 , mode='FAN_AVG',uniform=True, seed=None, dtype=tf.float32)\n",
        "    return tf.Variable(i(shape), name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IILZFt75Uc3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, 513], name=\"X\")\n",
        "y = tf.placeholder(tf.float32, [None, 513], name=\"y\")\n",
        "dropout_var = tf.placeholder(\"float\")\n",
        "\n",
        "def neural_net(X, dp):\n",
        "    # Input Layer with 513 units\n",
        "    weights_1 = weights([513, 513], \"weights_1\")\n",
        "    bias_1 = bias([513], \"bias_1\")\n",
        "\n",
        "    layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(X, weights_1) + bias_1), keep_prob = dp)\n",
        "\n",
        "    #First Hidden Layer with 1024 units\n",
        "    weights_2 = weights([513, 1024], \"weights_2\")\n",
        "    bias_2 = bias([1024], \"bias_2\")\n",
        "\n",
        "    layer_2 = tf.nn.dropout(tf.nn.relu(tf.matmul(layer_1, weights_2) + bias_2), keep_prob = dp)\n",
        "\n",
        "    #Second Hidden Layer with 1024 units\n",
        "    weights_3 = weights([1024, 1024], \"weights_3\")\n",
        "    bias_3 = bias([1024], \"bias_3\")\n",
        "\n",
        "    layer_3 = tf.nn.dropout(tf.nn.relu(tf.matmul(layer_2, weights_3) + bias_3), keep_prob = dp)\n",
        "\n",
        "    #Third Hidden Layer with 1024 units\n",
        "    weights_4 = weights([1024, 1024], \"weights_4\")\n",
        "    bias_4 = bias([1024], \"bias_4\")\n",
        "\n",
        "    layer_4 = tf.nn.dropout(tf.nn.relu(tf.matmul(layer_3, weights_4) + bias_4), keep_prob = dp)\n",
        "\n",
        "    #Fourth Hidden Layer with 1024 units\n",
        "    weights_5 = weights([1024, 1024], \"weights_5\")\n",
        "    bias_5 = bias([1024], \"bias_5\")\n",
        "\n",
        "    layer_5 = tf.nn.dropout(tf.nn.relu(tf.matmul(layer_4, weights_5) + bias_5), keep_prob = dp)\n",
        "\n",
        "    #Output layer with 513 units\n",
        "    output_weights = weights([1024, 513], \"output_weights\")\n",
        "    output_bias = bias([513], \"output_bias\")\n",
        "\n",
        "    output = tf.nn.relu(tf.matmul(layer_5, output_weights) + output_bias)\n",
        "\n",
        "    return ([output, layer_5, layer_4, layer_3, layer_2, layer_1])\n",
        "\n",
        "#Output \n",
        "out = neural_net(X, dropout_var)\n",
        "output = out[0]\n",
        "\n",
        "#Optimization\n",
        "cost = tf.reduce_mean(tf.losses.mean_squared_error(output, y)) \n",
        "train_optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "#Initializer\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "33bT_F78dONM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function to calculate SNR\n",
        "\n",
        "def SNR_function(s, s_pred):\n",
        "    \n",
        "    nlen = min(len(s), len(s_pred))\n",
        "    SNR = 10*math.log10((np.sum(s[:nlen]**2))/(np.sum((s[:nlen] - s_pred[:nlen])**2)))\n",
        "    \n",
        "    return SNR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cf_nHot4XaCY",
        "colab_type": "code",
        "outputId": "328ec1db-6ed3-4912-c033-78904cad3afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1949
        }
      },
      "cell_type": "code",
      "source": [
        "#Running model on training speech signal dataset and checking\n",
        "\n",
        "max_epochs = 570\n",
        "batch_size = 100\n",
        "step = 5\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    avg_cost = 0.\n",
        "    random = np.arange(0, 2459, 100)\n",
        "    np.random.shuffle(random)\n",
        "    \n",
        "    for i in range(len(random)):\n",
        "        start = int(random[i])\n",
        "        end = int(start + batch_size)\n",
        "        b_x, b_y = np.array(X_mod[start:end,:]), np.array(S_mod[start:end])\n",
        "        data = {X: b_x, y: b_y, dropout_var : 0.7}\n",
        "        sess.run(train_optimizer, feed_dict=data)\n",
        "        avg_cost += sess.run(cost, feed_dict=data)\n",
        "     \n",
        "    avg_cost = avg_cost / len(random)\n",
        "        \n",
        "    if (epoch+1) % step == 0:\n",
        "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, max_epochs, avg_cost))\n",
        "        data = {X: b_x, y: b_y, dropout_var : 1.}\n",
        "        train_out = sess.run(out, feed_dict=data)\n",
        "        train_output = sess.run(output, feed_dict=data)\n",
        "        \n",
        "        data = {X: X_mod, y: S_mod, dropout_var : 1.}\n",
        "        full_train_out = sess.run(out, feed_dict=data)\n",
        "        full_train_output = sess.run(output, feed_dict=data)\n",
        "        \n",
        "print (\"=========================Model Optimization Complete============================\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 004/570 cost: 0.044556595\n",
            "Epoch: 009/570 cost: 0.034643507\n",
            "Epoch: 014/570 cost: 0.035646060\n",
            "Epoch: 019/570 cost: 0.034003653\n",
            "Epoch: 024/570 cost: 0.031509107\n",
            "Epoch: 029/570 cost: 0.030037047\n",
            "Epoch: 034/570 cost: 0.029622766\n",
            "Epoch: 039/570 cost: 0.029048664\n",
            "Epoch: 044/570 cost: 0.032490938\n",
            "Epoch: 049/570 cost: 0.028431777\n",
            "Epoch: 054/570 cost: 0.028496795\n",
            "Epoch: 059/570 cost: 0.025769016\n",
            "Epoch: 064/570 cost: 0.027836792\n",
            "Epoch: 069/570 cost: 0.026764888\n",
            "Epoch: 074/570 cost: 0.026750831\n",
            "Epoch: 079/570 cost: 0.025101205\n",
            "Epoch: 084/570 cost: 0.028017273\n",
            "Epoch: 089/570 cost: 0.025363080\n",
            "Epoch: 094/570 cost: 0.023924638\n",
            "Epoch: 099/570 cost: 0.026550242\n",
            "Epoch: 104/570 cost: 0.031202120\n",
            "Epoch: 109/570 cost: 0.027349616\n",
            "Epoch: 114/570 cost: 0.024495057\n",
            "Epoch: 119/570 cost: 0.024037170\n",
            "Epoch: 124/570 cost: 0.024821224\n",
            "Epoch: 129/570 cost: 0.022245292\n",
            "Epoch: 134/570 cost: 0.021758784\n",
            "Epoch: 139/570 cost: 0.021557602\n",
            "Epoch: 144/570 cost: 0.020991417\n",
            "Epoch: 149/570 cost: 0.020321552\n",
            "Epoch: 154/570 cost: 0.020984436\n",
            "Epoch: 159/570 cost: 0.020565935\n",
            "Epoch: 164/570 cost: 0.021022401\n",
            "Epoch: 169/570 cost: 0.020637797\n",
            "Epoch: 174/570 cost: 0.019321406\n",
            "Epoch: 179/570 cost: 0.019789685\n",
            "Epoch: 184/570 cost: 0.019585115\n",
            "Epoch: 189/570 cost: 0.021302066\n",
            "Epoch: 194/570 cost: 0.022802644\n",
            "Epoch: 199/570 cost: 0.019816397\n",
            "Epoch: 204/570 cost: 0.021674646\n",
            "Epoch: 209/570 cost: 0.022215101\n",
            "Epoch: 214/570 cost: 0.019809326\n",
            "Epoch: 219/570 cost: 0.017998935\n",
            "Epoch: 224/570 cost: 0.020415841\n",
            "Epoch: 229/570 cost: 0.016973970\n",
            "Epoch: 234/570 cost: 0.019948554\n",
            "Epoch: 239/570 cost: 0.016565436\n",
            "Epoch: 244/570 cost: 0.018136144\n",
            "Epoch: 249/570 cost: 0.017303213\n",
            "Epoch: 254/570 cost: 0.016628300\n",
            "Epoch: 259/570 cost: 0.016820751\n",
            "Epoch: 264/570 cost: 0.021385925\n",
            "Epoch: 269/570 cost: 0.016949138\n",
            "Epoch: 274/570 cost: 0.019339034\n",
            "Epoch: 279/570 cost: 0.017230950\n",
            "Epoch: 284/570 cost: 0.019666327\n",
            "Epoch: 289/570 cost: 0.017583383\n",
            "Epoch: 294/570 cost: 0.016292511\n",
            "Epoch: 299/570 cost: 0.019260650\n",
            "Epoch: 304/570 cost: 0.016626098\n",
            "Epoch: 309/570 cost: 0.015801606\n",
            "Epoch: 314/570 cost: 0.015337103\n",
            "Epoch: 319/570 cost: 0.015364981\n",
            "Epoch: 324/570 cost: 0.014779487\n",
            "Epoch: 329/570 cost: 0.014534304\n",
            "Epoch: 334/570 cost: 0.014380476\n",
            "Epoch: 339/570 cost: 0.016302103\n",
            "Epoch: 344/570 cost: 0.014659511\n",
            "Epoch: 349/570 cost: 0.014966022\n",
            "Epoch: 354/570 cost: 0.014290309\n",
            "Epoch: 359/570 cost: 0.013723825\n",
            "Epoch: 364/570 cost: 0.014186385\n",
            "Epoch: 369/570 cost: 0.017413277\n",
            "Epoch: 374/570 cost: 0.014168657\n",
            "Epoch: 379/570 cost: 0.014381227\n",
            "Epoch: 384/570 cost: 0.013045831\n",
            "Epoch: 389/570 cost: 0.014973158\n",
            "Epoch: 394/570 cost: 0.016958232\n",
            "Epoch: 399/570 cost: 0.014398248\n",
            "Epoch: 404/570 cost: 0.013161777\n",
            "Epoch: 409/570 cost: 0.014812282\n",
            "Epoch: 414/570 cost: 0.012461754\n",
            "Epoch: 419/570 cost: 0.012843737\n",
            "Epoch: 424/570 cost: 0.014992391\n",
            "Epoch: 429/570 cost: 0.013816139\n",
            "Epoch: 434/570 cost: 0.013208247\n",
            "Epoch: 439/570 cost: 0.012712995\n",
            "Epoch: 444/570 cost: 0.012781456\n",
            "Epoch: 449/570 cost: 0.011984325\n",
            "Epoch: 454/570 cost: 0.011401814\n",
            "Epoch: 459/570 cost: 0.012091122\n",
            "Epoch: 464/570 cost: 0.011845692\n",
            "Epoch: 469/570 cost: 0.012639674\n",
            "Epoch: 474/570 cost: 0.011954261\n",
            "Epoch: 479/570 cost: 0.012553406\n",
            "Epoch: 484/570 cost: 0.013455352\n",
            "Epoch: 489/570 cost: 0.012167679\n",
            "Epoch: 494/570 cost: 0.012360316\n",
            "Epoch: 499/570 cost: 0.012400620\n",
            "Epoch: 504/570 cost: 0.011292303\n",
            "Epoch: 509/570 cost: 0.013649167\n",
            "Epoch: 514/570 cost: 0.011848643\n",
            "Epoch: 519/570 cost: 0.012565963\n",
            "Epoch: 524/570 cost: 0.011453205\n",
            "Epoch: 529/570 cost: 0.011306481\n",
            "Epoch: 534/570 cost: 0.011897339\n",
            "Epoch: 539/570 cost: 0.011313338\n",
            "Epoch: 544/570 cost: 0.010803072\n",
            "Epoch: 549/570 cost: 0.012181817\n",
            "Epoch: 554/570 cost: 0.012225628\n",
            "Epoch: 559/570 cost: 0.011240213\n",
            "Epoch: 564/570 cost: 0.011116659\n",
            "Epoch: 569/570 cost: 0.010452603\n",
            "=========================Model Optimization Complete============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9UXPlxWThaLr",
        "colab_type": "code",
        "outputId": "ec6d38ab-f846-4c44-d72f-c5455e9bf5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#SNR Calculation on whole dataset\n",
        "s_hat = (X_inp / np.abs(X_inp)) * np.transpose(full_train_output)\n",
        "s_pred = librosa.istft(s_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "s.shape\n",
        "s_pred.shape\n",
        "\n",
        "print (SNR_function(s,s_pred))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258899,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258496,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "stream",
          "text": [
            "12.481092631062156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bs5ir5c7xApl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "librosa.output.write_wav('train_recovered.wav', s_pred, sr)\n",
        "\n",
        "files.download('train_recovered.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKKy4_zswc9T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Getting output on Test datasets - 1 and 2**"
      ]
    },
    {
      "metadata": {
        "id": "gqwvsypvwi_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#On test signal 1\n",
        "\n",
        "data = {X: test1_mod, y : S_mod, dropout_var : 1.}\n",
        "test1_out = sess.run(out, feed_dict=data)\n",
        "test1_output = sess.run(output, feed_dict=data)\n",
        "\n",
        "test1_hat = (test1 / np.abs(test1)) * np.transpose(test1_output)\n",
        "test1_pred = librosa.istft(test1_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "\n",
        "librosa.output.write_wav('test_s_01_recons.wav', test1_pred, sr)\n",
        "\n",
        "files.download('test_s_01_recons.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gB2f0CPay45-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#On test signal 2\n",
        "\n",
        "data = {X: test2_mod, y : S_mod, dropout_var : 1.}\n",
        "test2_out = sess.run(out, feed_dict=data)\n",
        "test2_output = sess.run(output, feed_dict=data)\n",
        "\n",
        "test2_hat = (test2 / np.abs(test2)) * np.transpose(test2_output)\n",
        "test2_pred = librosa.istft(test2_hat, win_length = 1024, hop_length = 512)\n",
        "\n",
        "\n",
        "librosa.output.write_wav('test_s_02_recons.wav', test2_pred, sr)\n",
        "\n",
        "files.download('test_s_02_recons.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}